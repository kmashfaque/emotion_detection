{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b880b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfc7f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen=ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97b62261",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'images/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16676/2109342829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_generator=train_data_gen.flow_from_directory(\"images/train/\",\n\u001b[0m\u001b[0;32m      2\u001b[0m target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m validation_generator=train_data_gen.flow_from_directory(\"images/validation//\",\n\u001b[0;32m      5\u001b[0m target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    956\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m     \"\"\"\n\u001b[1;32m--> 958\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    959\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'images/train/'"
     ]
    }
   ],
   "source": [
    "train_generator=train_data_gen.flow_from_directory(\"C:/Users/HP/Desktop/AI/images/train/\",\n",
    "target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")\n",
    "\n",
    "validation_generator=train_data_gen.flow_from_directory(\"images/validation//\",\n",
    "target_size=(48,48),batch_size=64,color_mode=\"grayscale\",class_mode=\"categorical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4dd62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e526a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(32,kernel_size=(3,3),activation=\"relu\",input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64,kernel_size=(3,3),activation=\"relu\"))\n",
    "emotion_model.add(MaxPool2D(pool_size=(2,2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff56752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858664aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.compile(loss=\"categorical_crossentropy\",optimizer=Adam(learning_rate=0.0001, decay=1e-6), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5902a17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - 14s 987ms/step - loss: 1.6563 - accuracy: 0.3500 - val_loss: 1.5983 - val_accuracy: 0.3812\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.6652 - accuracy: 0.3078 - val_loss: 1.5784 - val_accuracy: 0.4031\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.6613 - accuracy: 0.3484 - val_loss: 1.5695 - val_accuracy: 0.4016\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.6675 - accuracy: 0.3297 - val_loss: 1.5909 - val_accuracy: 0.3922\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 34s 2s/step - loss: 1.6127 - accuracy: 0.3953 - val_loss: 1.5777 - val_accuracy: 0.4250\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 38s 4s/step - loss: 1.5787 - accuracy: 0.4094 - val_loss: 1.5757 - val_accuracy: 0.3969\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 24s 3s/step - loss: 1.6314 - accuracy: 0.3859 - val_loss: 1.5681 - val_accuracy: 0.4187\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.6525 - accuracy: 0.3500 - val_loss: 1.5782 - val_accuracy: 0.3891\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 8s 781ms/step - loss: 1.5874 - accuracy: 0.3969 - val_loss: 1.5772 - val_accuracy: 0.4047\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.5836 - accuracy: 0.3859 - val_loss: 1.6235 - val_accuracy: 0.3734\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 42s 5s/step - loss: 1.5446 - accuracy: 0.4297 - val_loss: 1.5372 - val_accuracy: 0.4094\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 39s 3s/step - loss: 1.5544 - accuracy: 0.3953 - val_loss: 1.5977 - val_accuracy: 0.3672\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 24s 3s/step - loss: 1.6399 - accuracy: 0.3562 - val_loss: 1.5670 - val_accuracy: 0.4266\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 18s 980ms/step - loss: 1.5836 - accuracy: 0.4031 - val_loss: 1.5788 - val_accuracy: 0.4062\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.5871 - accuracy: 0.4094 - val_loss: 1.5206 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 20s 1s/step - loss: 1.6203 - accuracy: 0.3688 - val_loss: 1.5735 - val_accuracy: 0.3938\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.5655 - accuracy: 0.4187 - val_loss: 1.5667 - val_accuracy: 0.3938\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 39s 4s/step - loss: 1.5440 - accuracy: 0.4234 - val_loss: 1.5619 - val_accuracy: 0.4187\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 28s 3s/step - loss: 1.5691 - accuracy: 0.3906 - val_loss: 1.5536 - val_accuracy: 0.4094\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.6107 - accuracy: 0.3359 - val_loss: 1.5702 - val_accuracy: 0.3844\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 40s 4s/step - loss: 1.5482 - accuracy: 0.4000 - val_loss: 1.5840 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 32s 3s/step - loss: 1.5732 - accuracy: 0.3828 - val_loss: 1.5913 - val_accuracy: 0.4016\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.5483 - accuracy: 0.4328 - val_loss: 1.5683 - val_accuracy: 0.4078\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.5625 - accuracy: 0.4062 - val_loss: 1.5641 - val_accuracy: 0.3969\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.5589 - accuracy: 0.4078 - val_loss: 1.5819 - val_accuracy: 0.3922\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 16s 1s/step - loss: 1.5725 - accuracy: 0.4016 - val_loss: 1.4900 - val_accuracy: 0.4406\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 24s 2s/step - loss: 1.5862 - accuracy: 0.4016 - val_loss: 1.5157 - val_accuracy: 0.4266\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.5572 - accuracy: 0.3891 - val_loss: 1.5628 - val_accuracy: 0.4031\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 7s 754ms/step - loss: 1.5629 - accuracy: 0.4109 - val_loss: 1.5243 - val_accuracy: 0.4406\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 9s 886ms/step - loss: 1.5758 - accuracy: 0.4016 - val_loss: 1.5275 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "emotion_model_info=emotion_model.fit_generator(\n",
    "train_generator,steps_per_epoch=10,epochs=30,validation_data=validation_generator,\n",
    "    validation_steps=10)\n",
    "\n",
    "model_json=emotion_model.to_json()\n",
    "\n",
    "with open(\"emotion_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "emotion_model.save_weights(\"emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74110e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432da02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
